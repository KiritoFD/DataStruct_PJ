#!/usr/bin/env python3
import csv
import json
import math
import os
import subprocess
import time
from pathlib import Path
from typing import Dict, List, Optional, Tuple

# é…ç½®
PARAM_BOUNDS = {
    "NUM_CENTROIDS": (64,3000),
    "NPROBE": (128,1024),
    "KMEAN_ITER": (4, 8),
}

CACHE_DIR = Path("tune")
CACHE_DIR.mkdir(parents=True, exist_ok=True)
SUM_CSV = CACHE_DIR / "sum.csv"
BEST_JSON = CACHE_DIR / "best_config.json"

CXX = os.environ.get("CXX", "g++")
CXXFLAGS = "-O3 -std=c++17 -pthread -march=native"
TIMEOUT_SEC = 1800

def stamp(params):
    return f"c{params['NUM_CENTROIDS']}_i{params['KMEAN_ITER']}_p{params['NPROBE']}"

class Cache:
    def __init__(self):
        self.data = {}
        if SUM_CSV.exists():
            with SUM_CSV.open() as f:
                for row in csv.DictReader(f):
                    try:
                        p = {k: int(row[k]) for k in PARAM_BOUNDS}
                        self.data[stamp(p)] = {
                            'params': p,
                            'recall': float(row['RECALL']) if row['RECALL'] != 'NA' else None,
                            'avg_time': float(row['AVG_QUERY_TIME_ms']) if row['AVG_QUERY_TIME_ms'] != 'NA' else None,
                            'build_time': float(row['INDEX_BUILD_TIME_s']) if row.get('INDEX_BUILD_TIME_s', 'NA') != 'NA' else None,
                            'status': row['STATUS']
                        }
                    except: 
                        pass

    def get(self, params):
        return self.data.get(stamp(params))

    def add(self, params, recall, avg_time, build_time, status):
        key = stamp(params)
        self.data[key] = {
            'params': params, 
            'recall': recall, 
            'avg_time': avg_time, 
            'build_time': build_time, 
            'status': status
        }
        
        header = not SUM_CSV.exists()
        with SUM_CSV.open('a') as f:
            w = csv.writer(f)
            if header:
                w.writerow([
                    'STAMP', 'NUM_CENTROIDS', 'KMEAN_ITER', 'NPROBE', 
                    'STATUS', 'ELAPSED_s', 'RECALL', 'AVG_QUERY_TIME_ms', 'INDEX_BUILD_TIME_s'
                ])
            w.writerow([
                key, params['NUM_CENTROIDS'], params['KMEAN_ITER'], params['NPROBE'],
                status, 'NA', recall or 'NA', avg_time or 'NA', build_time or 'NA'
            ])

def run_experiment(params, timeout):
    """è¿è¡Œå®éªŒå¹¶è¿”å›ç»“æœ"""
    stamp_str = stamp(params)
    logfile = CACHE_DIR / f"run_{stamp_str}.log"
    
    print(f"è¿è¡Œå®éªŒ: {stamp_str}")
    start_time = time.time()
    
    try:
        with open(logfile, 'w') as f:
            run_result = subprocess.run(
                ["timeout", f"{timeout}s", "./test", 
                 "--num-centroids", str(params['NUM_CENTROIDS']), 
                 "--kmean-iter", str(params['KMEAN_ITER']), 
                 "--nprob", str(params['NPROBE'])], 
                stdout=f, stderr=subprocess.STDOUT,
                timeout=timeout + 10
            )
        
        elapsed = time.time() - start_time
        
        if run_result.returncode == 124 or run_result.returncode == 137:
            return 'TIMEOUT', None, None, None
        elif run_result.returncode != 0:
            return f'ERROR_{run_result.returncode}', None, None, None
            
    except subprocess.TimeoutExpired:
        return 'TIMEOUT', None, None, None
    
    # è§£æç»“æœ
    recall = avg_time = build_time = None
    
    with open(logfile, 'r') as f:
        for line in f:
            line = line.strip()
            if "Average recall@" in line:
                try:
                    recall = float(line.split(":")[-1].strip())
                except:
                    pass
            elif "Average query time" in line:
                try:
                    avg_time = float(line.split(":")[-1].split()[0])
                except:
                    pass
            elif "Index build time" in line:
                try:
                    build_time = float(line.split(":")[-1].split()[0])
                except:
                    pass
    
    return 'OK', recall, avg_time, build_time

def evaluate_params(params, cache, timeout, target_recall):
    """è¯„ä¼°å‚æ•°é…ç½®"""
    cached = cache.get(params)
    if cached:
        return cached
    
    status, recall, avg_time, build_time = run_experiment(params, timeout)
    cache.add(params, recall, avg_time, build_time, status)
    
    result = {
        'params': params, 
        'recall': recall, 
        'avg_time': avg_time, 
        'build_time': build_time, 
        'status': status
    }
    
    # è®¡ç®—å¾—åˆ†ï¼šå¬å›ç‡è¾¾æ ‡æ—¶å¾—åˆ†=1/æŸ¥è¯¢æ—¶é—´ï¼Œå¦åˆ™ä¸ºè´Ÿåˆ†
    if status == 'OK' and recall is not None and avg_time is not None:
        if recall >= target_recall:
            result['score'] = (20-avg_time)*7+(recall-target_recall)*100  # æŸ¥è¯¢æ—¶é—´è¶Šå°ï¼Œå¾—åˆ†è¶Šé«˜
        else:
            # å¬å›ç‡ä¸è¶³ï¼Œæ ¹æ®å·®è·ç»™è´Ÿåˆ†
            result['score'] = avg_time+10**((target_recall-recall)*100) # å·®è·è¶Šå¤§æƒ©ç½šè¶Šå¤§
    else:
        result['score'] = -float('inf')
    
    return result

class AdaptiveSearch:
    def __init__(self, target_recall):
        self.target_recall = target_recall
        # åˆå§‹æœç´¢æ­¥é•¿ï¼ˆç›¸å¯¹æ¯”ä¾‹ï¼‰
        self.step_sizes = {
            'NUM_CENTROIDS': 0.05,  # 5% å˜åŒ–
            'NPROBE': 0.15,      # 15% å˜åŒ–
            'KMEAN_ITER': 0.05     # 5% å˜åŒ–ï¼ˆèŒƒå›´å°ï¼‰
        }
        self.min_step_sizes = {
            'NUM_CENTROIDS': 0.01,  # æœ€å°1%å˜åŒ–
            'NPROBE': 0.02,         # æœ€å°2%å˜åŒ–
            'KMEAN_ITER': 0.01      # æœ€å°1%å˜åŒ–
        }
        self.max_step_sizes = {
            'NUM_CENTROIDS': 0.3,   # æœ€å¤§30%å˜åŒ–
            'NPROBE': 0.4,          # æœ€å¤§40%å˜åŒ–
            'KMEAN_ITER': 0.2       # æœ€å¤§20%å˜åŒ–
        }
        
        # è·Ÿè¸ªå†å²æ”¹è¿›
        self.improvement_history = []
        self.consecutive_failures = 0
        
    def get_neighbors(self, params, last_improvement=None):
        """æ ¹æ®å†å²è¡¨ç°åŠ¨æ€ç”Ÿæˆé‚»å±…"""
        neighbors = []
        
        # åŸºç¡€æ–¹å‘ï¼šå¦‚æœä¸Šæ¬¡æœ‰æ”¹è¿›ï¼Œç»§ç»­ç±»ä¼¼æ–¹å‘
        base_directions = [1, -1]  # å¢åŠ å’Œå‡å°‘
        
        # å¦‚æœæœ‰æ˜æ˜¾çš„æ”¹è¿›æ–¹å‘ï¼ŒåŠ å¼ºè¯¥æ–¹å‘
        if last_improvement and len(self.improvement_history) > 2:
            recent_trend = sum(self.improvement_history[-3:]) / 3
            if abs(recent_trend) > 0.1:  # æœ‰æ˜æ˜¾è¶‹åŠ¿
                if recent_trend > 0:
                    base_directions = [1, 1, -1]  # åŠ å¼ºæ­£å‘
                else:
                    base_directions = [-1, -1, 1]  # åŠ å¼ºè´Ÿå‘
        
        for param_name in ['NUM_CENTROIDS', 'NPROBE', 'KMEAN_ITER']:
            current_val = params[param_name]
            step_size = self.step_sizes[param_name]
            
            # æ ¹æ®è¿ç»­å¤±è´¥æ¬¡æ•°è°ƒæ•´æ­¥é•¿
            if self.consecutive_failures > 3:
                step_size = max(step_size * 0.8, self.min_step_sizes[param_name])
            elif self.consecutive_failures == 0 and len(self.improvement_history) > 0:
                # è¿ç»­æˆåŠŸï¼Œé€‚å½“å¢å¤§æ­¥é•¿
                step_size = min(step_size * 1.1, self.max_step_sizes[param_name])
            
            for direction in base_directions:
                # è®¡ç®—æ–°å€¼ï¼ˆç›¸å¯¹å˜åŒ–ï¼‰
                if param_name == 'KMEAN_ITER':
                    # KMEAN_ITER ä½¿ç”¨ç»å¯¹å˜åŒ–
                    new_val = current_val + direction * max(1, int(current_val * step_size))
                else:
                    # å…¶ä»–å‚æ•°ä½¿ç”¨ç›¸å¯¹å˜åŒ–
                    new_val = int(current_val * (1 + direction * step_size))
                
                # ç¡®ä¿åœ¨è¾¹ç•Œå†…
                new_val = max(PARAM_BOUNDS[param_name][0], 
                            min(PARAM_BOUNDS[param_name][1], new_val))
                
                if new_val != current_val:
                    neighbor = params.copy()
                    neighbor[param_name] = new_val
                    neighbors.append(neighbor)
        
        # æ·»åŠ ä¸€äº›éšæœºç»„åˆçš„é‚»å±…ï¼ˆæ¢ç´¢æ–°æ–¹å‘ï¼‰
        if len(neighbors) < 8:  # å¦‚æœé‚»å±…å¤ªå°‘ï¼Œæ·»åŠ ä¸€äº›ç»„åˆ
            for _ in range(3):
                neighbor = params.copy()
                for param_name in ['NUM_CENTROIDS', 'NPROBE']:
                    direction = 1 if np.random.random() > 0.5 else -1
                    step_size = self.step_sizes[param_name] * (0.5 + np.random.random())
                    current_val = neighbor[param_name]
                    new_val = int(current_val * (1 + direction * step_size))
                    new_val = max(PARAM_BOUNDS[param_name][0], 
                                min(PARAM_BOUNDS[param_name][1], new_val))
                    neighbor[param_name] = new_val
                if stamp(neighbor) != stamp(params):
                    neighbors.append(neighbor)
        
        # å»é‡
        seen = set()
        unique_neighbors = []
        for neighbor in neighbors:
            key = stamp(neighbor)
            if key not in seen:
                seen.add(key)
                unique_neighbors.append(neighbor)
        
        return unique_neighbors
    
    def update_step_sizes(self, improvement_ratio):
        """æ ¹æ®æ”¹è¿›æƒ…å†µæ›´æ–°æ­¥é•¿"""
        self.improvement_history.append(improvement_ratio)
        
        if improvement_ratio > 0.01:  # æœ‰æ˜æ˜¾æ”¹è¿›
            self.consecutive_failures = 0
            # æˆåŠŸæ—¶ç¨å¾®å¢å¤§æ­¥é•¿ï¼ˆä½†ä¸è¶…è¿‡æœ€å¤§å€¼ï¼‰
            for param in self.step_sizes:
                self.step_sizes[param] = min(
                    self.step_sizes[param] * 1.05, 
                    self.max_step_sizes[param]
                )
        else:
            self.consecutive_failures += 1
            # å¤±è´¥æ—¶å‡å°æ­¥é•¿ï¼ˆä½†ä¸å°äºæœ€å°å€¼ï¼‰
            for param in self.step_sizes:
                self.step_sizes[param] = max(
                    self.step_sizes[param] * 0.9,
                    self.min_step_sizes[param]
                )
        
        # ä¿æŒå†å²é•¿åº¦
        if len(self.improvement_history) > 10:
            self.improvement_history.pop(0)

def adaptive_greedy_search(cache, init_params, target_recall, max_iterations, timeout):
    """è‡ªé€‚åº”è´ªå¿ƒæœç´¢ç®—æ³•"""
    current_params = init_params.copy()
    current_result = evaluate_params(current_params, cache, timeout, target_recall)
    best_result = current_result
    
    search_engine = AdaptiveSearch(target_recall)
    
    print(f"åˆå§‹é…ç½®: {current_params}")
    print(f"åˆå§‹ç»“æœ: å¬å›ç‡={current_result['recall']}, æŸ¥è¯¢æ—¶é—´={current_result['avg_time']}ms")
    print(f"åˆå§‹æ­¥é•¿: {search_engine.step_sizes}")
    
    last_score = current_result.get('score', -float('inf'))
    
    for iteration in range(max_iterations):
        print(f"\n--- è¿­ä»£ {iteration + 1} ---")
        print(f"å½“å‰æ­¥é•¿: {search_engine.step_sizes}")
        print(f"è¿ç»­å¤±è´¥: {search_engine.consecutive_failures}")
        
        # ç”Ÿæˆå¹¶è¯„ä¼°é‚»å±…
        neighbors = search_engine.get_neighbors(current_params)
        print(f"è¯„ä¼° {len(neighbors)} ä¸ªé‚»å±… (æ­¥é•¿: {search_engine.step_sizes})...")
        
        best_neighbor = None
        best_score = last_score
        
        neighbor_results = []
        for neighbor in neighbors:
            result = evaluate_params(neighbor, cache, timeout, target_recall)
            score = result.get('score', -float('inf'))
            neighbor_results.append((result, score))
            
            improvement = score - last_score
            status = "â†‘" if improvement > 0.001 else "â†“" if improvement < -0.001 else "â†’"
            
            print(f"  {status} é‚»å±… {neighbor}: å¬å›ç‡={result['recall']:.4f}, æ—¶é—´={result['avg_time']:.2f}ms, å¾—åˆ†={score:.6f}")
            
            if score > best_score + 1e-6:  # é¿å…æµ®ç‚¹è¯¯å·®
                best_score = score
                best_neighbor = result
        
        # æ›´æ–°æ­¥é•¿
        if best_neighbor:
            improvement_ratio = (best_score - last_score) / (abs(last_score) + 1e-6)
            search_engine.update_step_sizes(improvement_ratio)
        
        # å¦‚æœæ²¡æœ‰æ›´å¥½çš„é‚»å±…ï¼Œå°è¯•æ›´æ¿€è¿›çš„æœç´¢
        if best_neighbor is None and search_engine.consecutive_failures < 5:
            print("æœªæ‰¾åˆ°æ›´å¥½é‚»å±…ï¼Œå°è¯•æ‰©å¤§æœç´¢èŒƒå›´...")
            # ä¸´æ—¶å¢å¤§æ­¥é•¿
            original_steps = search_engine.step_sizes.copy()
            for param in search_engine.step_sizes:
                search_engine.step_sizes[param] = min(
                    search_engine.step_sizes[param] * 1.5,
                    search_engine.max_step_sizes[param]
                )
            
            # é‡æ–°ç”Ÿæˆé‚»å±…
            expanded_neighbors = search_engine.get_neighbors(current_params)
            for neighbor in expanded_neighbors:
                if any(stamp(neighbor) == stamp(n['params']) for n, _ in neighbor_results):
                    continue  # è·³è¿‡å·²è¯„ä¼°çš„
                    
                result = evaluate_params(neighbor, cache, timeout, target_recall)
                score = result.get('score', -float('inf'))
                
                improvement = score - last_score
                print(f"  *æ‰©å±•* é‚»å±… {neighbor}: å¬å›ç‡={result['recall']:.4f}, æ—¶é—´={result['avg_time']:.2f}ms, å¾—åˆ†={score:.6f}")
                
                if score > best_score + 1e-6:
                    best_score = score
                    best_neighbor = result
            
            # æ¢å¤æ­¥é•¿
            search_engine.step_sizes = original_steps
        
        # å¦‚æœè¿˜æ˜¯æ²¡æœ‰æ”¹è¿›ï¼Œåœæ­¢æœç´¢
        if best_neighbor is None:
            print("æ— æ³•æ‰¾åˆ°æ›´å¥½çš„é…ç½®ï¼Œåœæ­¢æœç´¢")
            break
        
        # ç§»åŠ¨åˆ°æœ€ä½³é‚»å±…
        current_params = best_neighbor['params'].copy()
        current_result = best_neighbor
        last_score = best_score
        
        # æ›´æ–°å…¨å±€æœ€ä½³
        if best_score > best_result.get('score', -float('inf')):
            best_result = current_result
            print(f"ğŸ¯ æ–°çš„æœ€ä½³é…ç½®: {best_result['params']}")
            print(f"   å¬å›ç‡={best_result['recall']:.4f}, æŸ¥è¯¢æ—¶é—´={best_result['avg_time']:.2f}ms")
        
        print(f"å½“å‰æœ€ä½³: {best_result['params']} (å¾—åˆ†={best_result.get('score', 'N/A'):.6f})")
        
        # æ”¶æ•›æ£€æŸ¥
        if search_engine.consecutive_failures >= 5 and all(
            sz <= min_sz * 1.1 for sz, min_sz in 
            zip(search_engine.step_sizes.values(), search_engine.min_step_sizes.values())
        ):
            print("æ­¥é•¿å·²æ”¶æ•›åˆ°æœ€å°å€¼ï¼Œåœæ­¢æœç´¢")
            break
    
    return best_result

def main():
    target_recall = 0.98
    init_params = {'NUM_CENTROIDS': 947, 'KMEAN_ITER': 6, 'NPROBE': 277}
    
    cache = Cache()
    
    print(f"ä¼˜åŒ–ç›®æ ‡: å¬å›ç‡ >= {target_recall}, æœ€å°åŒ–æŸ¥è¯¢æ—¶é—´")
    print(f"åˆå§‹å‚æ•°: {init_params}")
    print(f"è¶…æ—¶è®¾ç½®: {TIMEOUT_SEC}ç§’")
    print()
    
    best = adaptive_greedy_search(cache, init_params, target_recall, max_iterations=200, timeout=TIMEOUT_SEC)
    
    print(f"\n=== æœ€ç»ˆç»“æœ ===")
    print(f"æœ€ä½³å‚æ•°: {best['params']}")
    print(f"å¬å›ç‡: {best['recall']:.4f}")
    print(f"å¹³å‡æŸ¥è¯¢æ—¶é—´: {best['avg_time']:.2f}ms")
    if best['build_time']:
        print(f"ç´¢å¼•æ„å»ºæ—¶é—´: {best['build_time']:.2f}s")
    
    # ä¿å­˜ç»“æœ
    with open(BEST_JSON, 'w') as f:
        json.dump({
            'params': best['params'],
            'recall': best['recall'],
            'avg_query_time_ms': best['avg_time'],
            'index_build_time_s': best['build_time'],
            'status': best['status']
        }, f, indent=2)
    
    print(f"é…ç½®å·²ä¿å­˜è‡³: {BEST_JSON}")

if __name__ == "__main__":
    import numpy as np
    main()